{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wesly19-max/BIDA-A-Web-Based-Breast-Tumor-Image-Detection-Application-using-Convolutional-Neural-Networks/blob/main/Enb0_BIDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6KXvMt1RA16"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd8QBSWoRRfd"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "IMG_SIZE = (224, 224)  # Resize images to 224x224\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 300\n",
        "LEARNING_RATE = 0.0001\n",
        "DECAY_RATE = 0.95"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lERTOsW9RV3f"
      },
      "outputs": [],
      "source": [
        "# Path to your pre-determined train and test directories\n",
        "train_dir = '/content/drive/MyDrive/BreaKHis_Dataset/train'  # Modify with your train dataset directory\n",
        "test_dir = '/content/drive/MyDrive/BreaKHis_Dataset/test'    # Modify with your test dataset directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPGPDSbOTath"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Custom function to apply CLAHE, Gaussian Blur, and Sharpening\n",
        "def custom_preprocessing(image):\n",
        "    image = np.array(image * 255, dtype=np.uint8)  # Convert back to 0-255 range\n",
        "\n",
        "    # Convert to grayscale for CLAHE, then back to color\n",
        "    lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    l = clahe.apply(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "    # Apply Gaussian Blur\n",
        "    image = cv2.GaussianBlur(image, (3, 3), 0)\n",
        "\n",
        "    # Apply Sharpening\n",
        "    kernel = np.array([[0, -1, 0],\n",
        "                       [-1, 5, -1],\n",
        "                       [0, -1, 0]])\n",
        "    image = cv2.filter2D(image, -1, kernel)\n",
        "\n",
        "    return image / 255.0  # Normalize back to 0-1 range\n",
        "\n",
        "# Wrap the function for TensorFlow's pipeline\n",
        "def preprocess_function(image):\n",
        "    return tf.numpy_function(custom_preprocessing, [image], tf.float32)\n",
        "\n",
        "# Updated ImageDataGenerator with preprocessing function\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    preprocessing_function=preprocess_function  # Apply custom preprocessing\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYe_O5fvTeV-",
        "outputId": "1d627fb5-5994-4af4-aa2e-4f2f0cce80f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1148 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# Load pre-determined datasets (train and test data)\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='binary',  # Binary classification\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPzE49RDTgkj",
        "outputId": "5037e9ad-230e-432d-c5ba-f341c2f5791b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 545 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='binary',  # Binary classification\n",
        "    shuffle=False  # Set shuffle=False for test data to maintain the order\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QsLxvOnTj62"
      },
      "outputs": [],
      "source": [
        "# Prefetch datasets to optimize training speed\n",
        "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOFJ2kx2TmOR",
        "outputId": "67819fa7-5861-4dcb-a4f6-51bcf2b4f565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load MobileNetV3 Large pre-trained model\n",
        "base_model = EfficientNetB0(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSq6CZb0Tq8r"
      },
      "outputs": [],
      "source": [
        "# Freeze initial layers and fine-tune later layers\n",
        "for layer in base_model.layers[:200]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model.layers[150:]:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUSlnGl7TtK8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Define IMG_SHAPE here, or ensure it's defined globally\n",
        "IMG_SHAPE = (224, 224, 3)  # Example shape, adjust if necessary\n",
        "\n",
        "def create_model():\n",
        "    inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
        "    x = base_model(inputs, training=True)  # Enable training for base model\n",
        "\n",
        "    # Global pooling for better feature extraction\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # First fully connected layer with Swish activation\n",
        "    x = Dense(256, use_bias=False, kernel_regularizer=l2(0.0005))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"swish\")(x)\n",
        "\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Second fully connected layer\n",
        "    x = Dense(128, activation='swish', kernel_regularizer=l2(0.0005))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "\n",
        "    # Third fully connected layer\n",
        "    x = Dense(64, activation='swish', kernel_regularizer=l2(0.0005))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Output layer\n",
        "    x = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.0005))(x)\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "\n",
        "    # Compile with improved optimizer & loss function\n",
        "    model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.0001, weight_decay=1e-5),\n",
        "                  loss=\"binary_crossentropy\",\n",
        "                  metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mouEv6Q0TvTb"
      },
      "outputs": [],
      "source": [
        "# Compile model with learning rate decay\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=LEARNING_RATE,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=DECAY_RATE,\n",
        "    staircase=True\n",
        ")\n",
        "\n",
        "optimizer = SGD(learning_rate=lr_schedule, momentum=0.95, nesterov=True)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvLFDCCpUA_s"
      },
      "outputs": [],
      "source": [
        "# Early stopping to avoid overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Handle class imbalance by using class weights\n",
        "# Assuming class imbalance is likely, we'll calculate class weights\n",
        "class_weights = {0: 1.5, 1: 1.}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxAOic55UDLW"
      },
      "outputs": [],
      "source": [
        "# Early stopping to avoid overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdznaF4RUF_O",
        "outputId": "6045823a-0c50-43d2-fc18-0902505d1c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 10s/step - accuracy: 0.4847 - loss: 1.3160 - val_accuracy: 0.4624 - val_loss: 1.0411\n",
            "Epoch 2/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7s/step - accuracy: 0.5769 - loss: 1.1801 - val_accuracy: 0.5761 - val_loss: 1.0183\n",
            "Epoch 3/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 6s/step - accuracy: 0.6254 - loss: 1.0967 - val_accuracy: 0.6991 - val_loss: 0.9820\n",
            "Epoch 4/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 7s/step - accuracy: 0.6718 - loss: 1.0464 - val_accuracy: 0.7413 - val_loss: 0.9410\n",
            "Epoch 5/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7s/step - accuracy: 0.7426 - loss: 0.9438 - val_accuracy: 0.7633 - val_loss: 0.8991\n",
            "Epoch 6/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 7s/step - accuracy: 0.7505 - loss: 0.9412 - val_accuracy: 0.7927 - val_loss: 0.8645\n",
            "Epoch 7/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 6s/step - accuracy: 0.7840 - loss: 0.8668 - val_accuracy: 0.8055 - val_loss: 0.8369\n",
            "Epoch 8/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 6s/step - accuracy: 0.7701 - loss: 0.8825 - val_accuracy: 0.8183 - val_loss: 0.8183\n",
            "Epoch 9/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 6s/step - accuracy: 0.7743 - loss: 0.8712 - val_accuracy: 0.8257 - val_loss: 0.8020\n",
            "Epoch 10/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 6s/step - accuracy: 0.8338 - loss: 0.7808 - val_accuracy: 0.8239 - val_loss: 0.7917\n",
            "Epoch 11/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 6s/step - accuracy: 0.8075 - loss: 0.8341 - val_accuracy: 0.8349 - val_loss: 0.7806\n",
            "Epoch 12/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 6s/step - accuracy: 0.8347 - loss: 0.7649 - val_accuracy: 0.8385 - val_loss: 0.7681\n",
            "Epoch 13/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 6s/step - accuracy: 0.8477 - loss: 0.7695 - val_accuracy: 0.8404 - val_loss: 0.7615\n",
            "Epoch 14/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 7s/step - accuracy: 0.8224 - loss: 0.7661 - val_accuracy: 0.8422 - val_loss: 0.7528\n",
            "Epoch 15/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7s/step - accuracy: 0.8723 - loss: 0.7325 - val_accuracy: 0.8495 - val_loss: 0.7414\n",
            "Epoch 16/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - accuracy: 0.8624 - loss: 0.7234 - val_accuracy: 0.8514 - val_loss: 0.7332\n",
            "Epoch 17/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7s/step - accuracy: 0.8336 - loss: 0.7678 - val_accuracy: 0.8495 - val_loss: 0.7290\n",
            "Epoch 18/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 6s/step - accuracy: 0.8706 - loss: 0.7157 - val_accuracy: 0.8459 - val_loss: 0.7238\n",
            "Epoch 19/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 6s/step - accuracy: 0.8752 - loss: 0.7100 - val_accuracy: 0.8440 - val_loss: 0.7184\n",
            "Epoch 20/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 7s/step - accuracy: 0.8755 - loss: 0.6943 - val_accuracy: 0.8459 - val_loss: 0.7122\n",
            "Epoch 21/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 7s/step - accuracy: 0.8865 - loss: 0.6777 - val_accuracy: 0.8495 - val_loss: 0.7103\n",
            "Epoch 22/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7s/step - accuracy: 0.8871 - loss: 0.6713 - val_accuracy: 0.8532 - val_loss: 0.7025\n",
            "Epoch 23/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 7s/step - accuracy: 0.8986 - loss: 0.6675 - val_accuracy: 0.8606 - val_loss: 0.6965\n",
            "Epoch 24/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7s/step - accuracy: 0.8869 - loss: 0.6599 - val_accuracy: 0.8587 - val_loss: 0.6906\n",
            "Epoch 25/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 7s/step - accuracy: 0.9078 - loss: 0.6271 - val_accuracy: 0.8606 - val_loss: 0.6868\n",
            "Epoch 26/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 7s/step - accuracy: 0.8981 - loss: 0.6317 - val_accuracy: 0.8642 - val_loss: 0.6834\n",
            "Epoch 27/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 6s/step - accuracy: 0.9155 - loss: 0.6226 - val_accuracy: 0.8642 - val_loss: 0.6778\n",
            "Epoch 28/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 7s/step - accuracy: 0.9078 - loss: 0.6247 - val_accuracy: 0.8606 - val_loss: 0.6759\n",
            "Epoch 29/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - accuracy: 0.9258 - loss: 0.5989 - val_accuracy: 0.8624 - val_loss: 0.6742\n",
            "Epoch 30/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - accuracy: 0.9043 - loss: 0.6299 - val_accuracy: 0.8642 - val_loss: 0.6718\n",
            "Epoch 31/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - accuracy: 0.9159 - loss: 0.5956 - val_accuracy: 0.8661 - val_loss: 0.6671\n",
            "Epoch 32/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 7s/step - accuracy: 0.9338 - loss: 0.5637 - val_accuracy: 0.8661 - val_loss: 0.6648\n",
            "Epoch 33/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7s/step - accuracy: 0.9504 - loss: 0.5585 - val_accuracy: 0.8661 - val_loss: 0.6630\n",
            "Epoch 34/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - accuracy: 0.9261 - loss: 0.5617 - val_accuracy: 0.8697 - val_loss: 0.6593\n",
            "Epoch 35/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 7s/step - accuracy: 0.9319 - loss: 0.5816 - val_accuracy: 0.8734 - val_loss: 0.6533\n",
            "Epoch 36/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 7s/step - accuracy: 0.9418 - loss: 0.5428 - val_accuracy: 0.8771 - val_loss: 0.6475\n",
            "Epoch 37/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 7s/step - accuracy: 0.9484 - loss: 0.5315 - val_accuracy: 0.8771 - val_loss: 0.6450\n",
            "Epoch 38/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 7s/step - accuracy: 0.9408 - loss: 0.5469 - val_accuracy: 0.8789 - val_loss: 0.6421\n",
            "Epoch 39/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - accuracy: 0.9421 - loss: 0.5415 - val_accuracy: 0.8771 - val_loss: 0.6406\n",
            "Epoch 40/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - accuracy: 0.9427 - loss: 0.5464 - val_accuracy: 0.8807 - val_loss: 0.6370\n",
            "Epoch 41/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 6s/step - accuracy: 0.9382 - loss: 0.5382 - val_accuracy: 0.8844 - val_loss: 0.6336\n",
            "Epoch 42/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 7s/step - accuracy: 0.9486 - loss: 0.5191 - val_accuracy: 0.8844 - val_loss: 0.6326\n",
            "Epoch 43/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - accuracy: 0.9576 - loss: 0.5167 - val_accuracy: 0.8826 - val_loss: 0.6306\n",
            "Epoch 44/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 7s/step - accuracy: 0.9441 - loss: 0.5168 - val_accuracy: 0.8807 - val_loss: 0.6290\n",
            "Epoch 45/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 7s/step - accuracy: 0.9606 - loss: 0.5220 - val_accuracy: 0.8844 - val_loss: 0.6287\n",
            "Epoch 46/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 7s/step - accuracy: 0.9574 - loss: 0.5122 - val_accuracy: 0.8844 - val_loss: 0.6285\n",
            "Epoch 47/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 7s/step - accuracy: 0.9576 - loss: 0.5005 - val_accuracy: 0.8862 - val_loss: 0.6260\n",
            "Epoch 48/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 6s/step - accuracy: 0.9721 - loss: 0.4745 - val_accuracy: 0.8844 - val_loss: 0.6253\n",
            "Epoch 49/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7s/step - accuracy: 0.9630 - loss: 0.4841 - val_accuracy: 0.8862 - val_loss: 0.6222\n",
            "Epoch 50/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 7s/step - accuracy: 0.9424 - loss: 0.5203 - val_accuracy: 0.8862 - val_loss: 0.6228\n",
            "Epoch 51/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 6s/step - accuracy: 0.9486 - loss: 0.4933 - val_accuracy: 0.8899 - val_loss: 0.6221\n",
            "Epoch 52/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 7s/step - accuracy: 0.9668 - loss: 0.4722 - val_accuracy: 0.8899 - val_loss: 0.6202\n",
            "Epoch 53/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 6s/step - accuracy: 0.9658 - loss: 0.4819 - val_accuracy: 0.8881 - val_loss: 0.6194\n",
            "Epoch 54/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 6s/step - accuracy: 0.9582 - loss: 0.4910 - val_accuracy: 0.8881 - val_loss: 0.6191\n",
            "Epoch 55/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7s/step - accuracy: 0.9628 - loss: 0.4681 - val_accuracy: 0.8881 - val_loss: 0.6178\n",
            "Epoch 56/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7s/step - accuracy: 0.9478 - loss: 0.5045 - val_accuracy: 0.8899 - val_loss: 0.6150\n",
            "Epoch 57/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 7s/step - accuracy: 0.9748 - loss: 0.4557 - val_accuracy: 0.8936 - val_loss: 0.6143\n",
            "Epoch 58/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 7s/step - accuracy: 0.9747 - loss: 0.4607 - val_accuracy: 0.8899 - val_loss: 0.6132\n",
            "Epoch 59/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - accuracy: 0.9683 - loss: 0.4800 - val_accuracy: 0.8917 - val_loss: 0.6116\n",
            "Epoch 60/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - accuracy: 0.9665 - loss: 0.4633 - val_accuracy: 0.8899 - val_loss: 0.6114\n",
            "Epoch 61/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 7s/step - accuracy: 0.9659 - loss: 0.4771 - val_accuracy: 0.8899 - val_loss: 0.6112\n",
            "Epoch 62/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 6s/step - accuracy: 0.9601 - loss: 0.4885 - val_accuracy: 0.8917 - val_loss: 0.6091\n",
            "Epoch 63/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 6s/step - accuracy: 0.9755 - loss: 0.4475 - val_accuracy: 0.8936 - val_loss: 0.6087\n",
            "Epoch 64/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 6s/step - accuracy: 0.9798 - loss: 0.4391 - val_accuracy: 0.8936 - val_loss: 0.6098\n",
            "Epoch 65/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 6s/step - accuracy: 0.9684 - loss: 0.4529 - val_accuracy: 0.8917 - val_loss: 0.6113\n",
            "Epoch 66/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 6s/step - accuracy: 0.9757 - loss: 0.4527 - val_accuracy: 0.8917 - val_loss: 0.6098\n",
            "Epoch 67/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 6s/step - accuracy: 0.9708 - loss: 0.4491 - val_accuracy: 0.9009 - val_loss: 0.6078\n",
            "Epoch 68/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 6s/step - accuracy: 0.9778 - loss: 0.4478 - val_accuracy: 0.9028 - val_loss: 0.6060\n",
            "Epoch 69/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 6s/step - accuracy: 0.9742 - loss: 0.4447 - val_accuracy: 0.9009 - val_loss: 0.6058\n",
            "Epoch 70/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 7s/step - accuracy: 0.9684 - loss: 0.4494 - val_accuracy: 0.8972 - val_loss: 0.6059\n",
            "Epoch 71/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 7s/step - accuracy: 0.9647 - loss: 0.4596 - val_accuracy: 0.8991 - val_loss: 0.6058\n",
            "Epoch 72/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 7s/step - accuracy: 0.9824 - loss: 0.4336 - val_accuracy: 0.8991 - val_loss: 0.6054\n",
            "Epoch 73/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 7s/step - accuracy: 0.9863 - loss: 0.4199 - val_accuracy: 0.8991 - val_loss: 0.6056\n",
            "Epoch 74/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 7s/step - accuracy: 0.9817 - loss: 0.4180 - val_accuracy: 0.8972 - val_loss: 0.6062\n",
            "Epoch 75/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 6s/step - accuracy: 0.9761 - loss: 0.4267 - val_accuracy: 0.9009 - val_loss: 0.6055\n",
            "Epoch 76/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 6s/step - accuracy: 0.9797 - loss: 0.4325 - val_accuracy: 0.9009 - val_loss: 0.6058\n",
            "Epoch 77/300\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 6s/step - accuracy: 0.9714 - loss: 0.4462 - val_accuracy: 0.9009 - val_loss: 0.6063\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,  # Use the test dataset for validation\n",
        "    validation_data=test_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping],\n",
        "    class_weight=class_weights  # Apply class weights during training\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1OdNzFfY_nkP"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation accuracy\n",
        "def plot_accuracy(history):\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    plot_accuracy(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9CnMKzp_too"
      },
      "outputs": [],
      "source": [
        "# Evaluate model performance on test data\n",
        "y_pred_raw = model.predict(test_dataset)\n",
        "y_pred = (y_pred_raw > 0.5).astype(int)  # Apply threshold for binary classification\n",
        "\n",
        "# Get true labels\n",
        "y_true = []\n",
        "for images, labels in test_dataset:\n",
        "    y_true.extend(labels.numpy())\n",
        "\n",
        "# Convert to numpy for confusion matrix and metrics\n",
        "y_true = np.array(y_true)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VD9-Qcv0ESFb",
        "outputId": "005e2f8d-3703-4689-8a8c-933ca50f58ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.9252\n",
            "Precision: 0.9290\n",
            "Recall: 0.9214\n"
          ]
        }
      ],
      "source": [
        "# Calculate performance metrics\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    f1 = f1_score(y_true, y_pred, average='binary')  # F1 for binary classification\n",
        "    precision = precision_score(y_true, y_pred, average='binary')\n",
        "    recall = recall_score(y_true, y_pred, average='binary')\n",
        "\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "compute_metrics(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU3SHeK8cB80"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(history):\n",
        "    \"\"\"\n",
        "    Plots the training and validation loss over epochs.\n",
        "    :param history: Keras history object from model.fit()\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(history.history['loss'], label='Training Loss', linestyle='-', marker='o')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss', linestyle='-', marker='o')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss Over Epochs')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "plot_loss(history)\n",
        "\n",
        "# Example usage (assuming you have a history object from model.fit())\n",
        "# plot_loss(history)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LfYVT02xox7oSrNLeAiZNdYGalnCEKff",
      "authorship_tag": "ABX9TyPbh3Z4LUu6DFuby+KNcFO1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}